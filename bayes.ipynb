{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adatok letöltése"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_datasets as tfds\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Adathalmaz letöltése\n",
    "dataset_train = tfds.load('imdb_reviews', split='train', shuffle_files=True)\n",
    "dataset_test = tfds.load('imdb_reviews', split='test', shuffle_files=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_df(dataset):\n",
    "    data = [{ 'text': item['text'].numpy().decode('utf-8'), 'label': item['label'].numpy() } for item in tqdm(dataset)]\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "df_train = convert_to_df(dataset_train)\n",
    "df_test = convert_to_df(dataset_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(value):\n",
    "    if(value == 1):\n",
    "        return \"positive\"\n",
    "    else:\n",
    "        return \"negative\"\n",
    "\n",
    "df_train[\"sentiment\"] = [None] * len(df_train)\n",
    "df_train[\"sentiment\"] = df_train[\"label\"].apply(sentiment)\n",
    "df_test[\"sentiment\"] = [None] * len(df_test)\n",
    "df_test[\"sentiment\"] = df_test[\"label\"].apply(sentiment)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adattiszítás"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "STOPWORDS = stopwords.words(\"english\")\n",
    "\n",
    "STOPWORDS[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    soup = BeautifulSoup(text, 'html.parser')\n",
    "    text = soup.get_text()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"text\"] = df_train[\"text\"].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')\n",
    "\n",
    "tokenized_reviews = df_train[\"text\"].apply(lambda review_text: word_tokenize(review_text.replace(\"\\n\",\"\").lower()))\n",
    "\n",
    "tokenized_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict()\n",
    "\n",
    "for review in tqdm(tokenized_reviews):\n",
    "    for word in review:\n",
    "        if word not in STOPWORDS and word.isalpha():\n",
    "            d[word] = d.get(word, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sorted(d.items(), key=lambda item: item[1], reverse=True)\n",
    "d[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DESIRED_VOCAB_SIZE = 4000\n",
    "\n",
    "VOCAB = [k for k,v in d[:DESIRED_VOCAB_SIZE]]\n",
    "word_table = pd.DataFrame({\"word\": VOCAB})\n",
    "word_table.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
